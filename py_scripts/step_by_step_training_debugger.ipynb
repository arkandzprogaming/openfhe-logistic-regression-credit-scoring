{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bc0082",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "- provide a plaintext interface to analyze step-by-step what is happening in the encrypted code\n",
    "\n",
    "- Used as a Python sanity check because I'm not that familiar with R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91303fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from numba import njit\n",
    "\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a827",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e34725-f22a-4ce4-bc21-3967727b0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def load_data(num_samples, compare_to_r_ref):\n",
    "    x_file = \"../train_data/X_norm_1024.csv\"\n",
    "    y_file = \"../train_data/y_1024.csv\"\n",
    "    train_x = pd.read_csv(x_file)\n",
    "    train_x = train_x.to_numpy()[:num_samples]\n",
    "    train_y = pd.read_csv(y_file)\n",
    "    train_y = train_y.to_numpy()[:num_samples]\n",
    "    print(f\"{bcolors.OKGREEN}Using subsampled data to compare Python-C++{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKGREEN}Reading in {x_file}, {y_file} {bcolors.ENDC}\")\n",
    "\n",
    "    print(f\"Train X shape is: {train_x.shape}\")\n",
    "    print(f\"Train y shape is: {train_y.shape}\")\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce32218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mUsing subsampled data to compare Python-C++\u001b[0m\n",
      "\u001b[92mReading in ../train_data/X_norm_1024.csv, ../train_data/y_1024.csv \u001b[0m\n",
      "Train X shape is: (1023, 10)\n",
      "Train y shape is: (1023, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = -1\n",
    "COMPARE_TO_R_REF = False\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "train_x, train_y = load_data(\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    compare_to_r_ref=COMPARE_TO_R_REF\n",
    ")\n",
    "\n",
    "# Same shape as Marcelo's reference code\n",
    "betas = np.zeros((10, ))\n",
    "betas = np.random.uniform(-0.1, 0.1, 10)\n",
    "betas = np.random.randn(10) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac264a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas   # A vector of linear_predictions/logits z = train_x @ weights\n",
    "    if dbg:\n",
    "        print(f\"Logits: {preds}\")\n",
    "    return np.expand_dims(sigmoid(preds), -1)   # Shape: (m, 1)\n",
    "\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)   # A vector of logistic predictions y_hat = sigmoid(z)\n",
    "    gradient = -train_x.T @ (train_y - preds) / len(train_y)\n",
    "    return gradient   # Shape: (10, 1) == Rows correspond to num_features\n",
    "    ## This function is used to update the values of betas: w_new = w_old + lr * gradient\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))   # h: hypothesis, basically preds/y_hat\n",
    "    t1 = np.matmul(-y.T, np.log(h))\n",
    "    t2_a = (1 - y.T)\n",
    "    t2_b = np.log(np.clip(1 - h, 0.000000000000001, np.max(1 - h)))  # Used to get numerical issues\n",
    "    ## np.clip() function prevents computing the log of 0, by taking the minimum of 1e-15.\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "\n",
    "    return ((t1 - t2) / m)[0]   # Shape: (1,) == scalar value\n",
    "\n",
    "def nesterov(betas, epochs, lr, mu, train_x, train_y):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    # for i in tqdm.trange(epochs):\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "\n",
    "        ## Assign updated weights into phi_prime\n",
    "        phi_prime = theta - lr * np.squeeze(gradient)   # np.squeeze() removes single dimensions --> shape (10,)\n",
    "        \n",
    "        ## Nesterov acceleration process\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            ## If current updated weight (phi_prime) < previous weight (phi), \n",
    "            ## The updated weight theta will be even smaller.\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "        phi = phi_prime   # phi is then the weight of the previous epoch/update\n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        nesterov_loss[i] = loss\n",
    "\n",
    "        # print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return nesterov_loss, theta, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74a3d18-2a23-46e6-897a-2dc859beb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, theta, phi = nesterov(betas, 200, lr, mu, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745a6998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6812155165482665,\n",
       " 0.6701553917502939,\n",
       " 0.6597774766250945,\n",
       " 0.6500832775052069,\n",
       " 0.6410014956245764,\n",
       " 0.6324669733017375,\n",
       " 0.6244252707678345,\n",
       " 0.6168308106865237,\n",
       " 0.6096449646013661,\n",
       " 0.6028345610285551,\n",
       " 0.5963707562049805,\n",
       " 0.5902281809178755,\n",
       " 0.5843842937150668,\n",
       " 0.5788188876879484,\n",
       " 0.5735137113665079,\n",
       " 0.5684521744304052,\n",
       " 0.5636191165796894,\n",
       " 0.5590006236029212,\n",
       " 0.55458387889821,\n",
       " 0.5503570418116154,\n",
       " 0.5463091464403759,\n",
       " 0.5424300162201237,\n",
       " 0.5387101908368336,\n",
       " 0.5351408628958031,\n",
       " 0.531713822430348,\n",
       " 0.5284214078075234,\n",
       " 0.5252564619350135,\n",
       " 0.522212292927371,\n",
       " 0.5192826385765259,\n",
       " 0.5164616341094356,\n",
       " 0.5137437828183132,\n",
       " 0.5111239292257703,\n",
       " 0.5085972345054297,\n",
       " 0.5061591539231828,\n",
       " 0.5038054160989116,\n",
       " 0.5015320039158202,\n",
       " 0.49933513692640485,\n",
       " 0.497211255121923,\n",
       " 0.49515700394697815,\n",
       " 0.49316922045325373,\n",
       " 0.49124492049702684,\n",
       " 0.4893812868942434,\n",
       " 0.4875756584549551,\n",
       " 0.4858255198259803,\n",
       " 0.4841284920769497,\n",
       " 0.4824823239705289,\n",
       " 0.48088488386268663,\n",
       " 0.4793341521834629,\n",
       " 0.47782821445285445,\n",
       " 0.47636525479021236,\n",
       " 0.47494354987899734,\n",
       " 0.47356146335187677,\n",
       " 0.4722174405640188,\n",
       " 0.47091000372506364,\n",
       " 0.4696377473626462,\n",
       " 0.4683993340925444,\n",
       " 0.4671934906725332,\n",
       " 0.4660190043188641,\n",
       " 0.4648747192659772,\n",
       " 0.46375953355159233,\n",
       " 0.46267239601074683,\n",
       " 0.4616123034636357,\n",
       " 0.4605782980833068,\n",
       " 0.4595694649303484,\n",
       " 0.4585849296427085,\n",
       " 0.45762385626970237,\n",
       " 0.45668544524010807,\n",
       " 0.4557689314550197,\n",
       " 0.4548735824968422,\n",
       " 0.4539986969464603,\n",
       " 0.453143602801215,\n",
       " 0.4523076559868738,\n",
       " 0.4514902389572826,\n",
       " 0.45069075937586084,\n",
       " 0.4499086488735229,\n",
       " 0.4491433618780102,\n",
       " 0.4483943745099781,\n",
       " 0.4476611835415203,\n",
       " 0.4469433054131201,\n",
       " 0.4462402753053053,\n",
       " 0.44555164626154625,\n",
       " 0.44487698835917666,\n",
       " 0.44421588792534794,\n",
       " 0.4435679467952271,\n",
       " 0.442932781609847,\n",
       " 0.4423100231511905,\n",
       " 0.44169931571225646,\n",
       " 0.4411003165000074,\n",
       " 0.4405126950692377,\n",
       " 0.4399361327855335,\n",
       " 0.43937032231561673,\n",
       " 0.43881496714347457,\n",
       " 0.4382697811107842,\n",
       " 0.43773448798023634,\n",
       " 0.43720882102045133,\n",
       " 0.4366925226112654,\n",
       " 0.4361853438682433,\n",
       " 0.43568704428534294,\n",
       " 0.43519739139472774,\n",
       " 0.4347161604427817,\n",
       " 0.43424313408144605,\n",
       " 0.433778102074042,\n",
       " 0.4333208610148041,\n",
       " 0.4328712140613876,\n",
       " 0.43242897067966457,\n",
       " 0.43199394640015826,\n",
       " 0.43156596258550806,\n",
       " 0.4311448462083916,\n",
       " 0.43073042963936314,\n",
       " 0.4303225504441014,\n",
       " 0.4299210511895863,\n",
       " 0.42952577925875407,\n",
       " 0.4291365866732044,\n",
       " 0.4287533299235581,\n",
       " 0.4283758698070856,\n",
       " 0.42800407127224926,\n",
       " 0.4276378032698207,\n",
       " 0.42727693861025384,\n",
       " 0.42692135382701174,\n",
       " 0.4265709290455622,\n",
       " 0.4262255478577714,\n",
       " 0.42588509720144024,\n",
       " 0.4255494672447423,\n",
       " 0.4252185512753329,\n",
       " 0.42489224559391375,\n",
       " 0.424570449412047,\n",
       " 0.4242530647540237,\n",
       " 0.4239399963626025,\n",
       " 0.42363115160844217,\n",
       " 0.4233264404030636,\n",
       " 0.423025775115181,\n",
       " 0.42272907049025504,\n",
       " 0.422436243573123,\n",
       " 0.42214721363357327,\n",
       " 0.42186190209473357,\n",
       " 0.42158023246415177,\n",
       " 0.42130213026745306,\n",
       " 0.4210275229844631,\n",
       " 0.4207563399876914,\n",
       " 0.42048851248307506,\n",
       " 0.42022397345288803,\n",
       " 0.419962657600725,\n",
       " 0.4197045012984729,\n",
       " 0.419449442535188,\n",
       " 0.4191974208678003,\n",
       " 0.4189483773735705,\n",
       " 0.4187022546042267,\n",
       " 0.4184589965417154,\n",
       " 0.4182185485554988,\n",
       " 0.417980857361338,\n",
       " 0.41774587098150395,\n",
       " 0.4175135387063568,\n",
       " 0.41728381105724166,\n",
       " 0.41705663975064855,\n",
       " 0.416831977663588,\n",
       " 0.416609778800133,\n",
       " 0.41638999825908507,\n",
       " 0.4161725922027189,\n",
       " 0.41595751782656576,\n",
       " 0.41574473333019585,\n",
       " 0.41553419788896107,\n",
       " 0.41532587162666357,\n",
       " 0.4151197155891139,\n",
       " 0.41491569171854675,\n",
       " 0.41471376282886113,\n",
       " 0.414513892581657,\n",
       " 0.4143160454630358,\n",
       " 0.4141201867611404,\n",
       " 0.4139262825444045,\n",
       " 0.41373429964048886,\n",
       " 0.41354420561587624,\n",
       " 0.413355968756105,\n",
       " 0.41316955804661565,\n",
       " 0.4129849431541908,\n",
       " 0.41280209440896537,\n",
       " 0.4126209827869894,\n",
       " 0.4124415798933224,\n",
       " 0.4122638579456412,\n",
       " 0.41208778975834376,\n",
       " 0.4119133487271315,\n",
       " 0.4117405088140542,\n",
       " 0.41156924453300076,\n",
       " 0.41139953093562176,\n",
       " 0.41123134359766794,\n",
       " 0.41106465860573194,\n",
       " 0.4108994525443785,\n",
       " 0.41073570248365154,\n",
       " 0.4105733859669431,\n",
       " 0.41041248099921585,\n",
       " 0.4102529660355633,\n",
       " 0.41009481997010083,\n",
       " 0.40993802212517244,\n",
       " 0.4097825522408672,\n",
       " 0.4096283904648312,\n",
       " 0.4094755173423695,\n",
       " 0.4093239138068253,\n",
       " 0.4091735611702294,\n",
       " 0.40902444111421066,\n",
       " 0.4088765356811597,\n",
       " 0.4087298272656373]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses\n",
    "\n",
    "## zero initialized betas    : cost = 0.4087381183990924\n",
    "## uniform initialized betas : cost = 0.40867096414830645\n",
    "## randn initialized betas   : cost = 0.40850863604124726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1f5f95-8319-4c52-96f7-9accd6387d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25031844,  0.2002066 , -1.18935318,  0.42938639, -0.64430861,\n",
       "       -0.05019797, -0.08696701, -0.36465605,  0.11685985,  0.4454505 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57becf84-9bb0-45f0-a969-f64a5789ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25004521,  0.20012118, -1.18916174,  0.42939299, -0.64428704,\n",
       "       -0.05027591, -0.08692788, -0.36454147,  0.11683475,  0.44529883])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f32b31a-e349-435e-a5b9-e478f7ce2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = fwd(train_x, theta, dbg=False)\n",
    "\n",
    "## Decision (Threshold = 0.5)\n",
    "train_y_hat = (pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2c4881-5393-4543-af7a-35d8911bf7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a522e7-33c1-446e-9623-967aba4218e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb4254f-d93b-43cd-bfe5-4934efbfbf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463,  48],\n",
       "       [136, 376]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_y, train_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "720e704c-80aa-4b39-8fde-4fae7367bb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820136852394917"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, train_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20ef3c-c366-4bd1-a272-cd3b762ee71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
