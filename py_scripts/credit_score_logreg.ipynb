{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab2dd2e-97ae-441b-a3ad-8fa37f50e703",
   "metadata": {},
   "source": [
    "# Credit score classification using logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f92936-ae0e-4a91-becb-b274541a008d",
   "metadata": {},
   "source": [
    "We are using a credit-related dataset found in Kaggle (source: https://www.kaggle.com/datasets/parisrohan/credit-score-classification/data). The dataset consists of 27 input features and one target label, that is the credit score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482adc8-bb1b-4458-8d73-7457db8e82ae",
   "metadata": {},
   "source": [
    "Goal : To predict the credit score of a new, unseen data using logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4766b21f-e8c0-43a6-86df-f89f2d11da45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from numba import njit\n",
    "\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ed538-0687-4235-9e4b-9526f7397194",
   "metadata": {},
   "source": [
    "## Load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64034e0b-460c-4d41-8478-516cf9a866a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    filename = \"../train_data/cs_train.csv\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    ## Separate target from features\n",
    "    X = df.drop(columns=['Credit_Score'])\n",
    "    y = df['Credit_Score']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c654aa-4cb0-4733-a1dd-1117e1ec4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_split(X, y, num_samples, compare_to_r_ref):\n",
    "    X = X.to_numpy()[:num_samples]\n",
    "    y = y.to_numpy()[:num_samples]\n",
    "    \n",
    "    ## Split into training and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1332)\n",
    "    \n",
    "    print(f\"Train X shape is: {X_train.shape}\")\n",
    "    print(f\"Train Y shape is: {y_train.shape}\")\n",
    "    print(f\"Test X shape is: {X_test.shape}\")\n",
    "    print(f\"Test Y shape is: {y_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95631795-2313-4740-8e98-9fdb16e3b426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31302/566418612.py:3: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1602</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>22 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.41529543900253</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.49408867943663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1603</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.28022162236736</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.62916249607184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1604</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>March</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>-500</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>22 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521264648</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.2098628537912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1605</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>22 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.4580743910713</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.45130972736786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1606</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>22 Years and 5 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153086217326</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.48923103222177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID Customer_ID     Month           Name   Age          SSN Occupation  \\\n",
       "0  0x1602   CUS_0xd40   January  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "1  0x1603   CUS_0xd40  February  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "2  0x1604   CUS_0xd40     March  Aaron Maashoh  -500  821-00-0265  Scientist   \n",
       "3  0x1605   CUS_0xd40     April  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "4  0x1606   CUS_0xd40       May  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "\n",
       "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
       "0      19114.12            1824.843333                  3  ...   \n",
       "1      19114.12                    NaN                  3  ...   \n",
       "2      19114.12                    NaN                  3  ...   \n",
       "3      19114.12                    NaN                  3  ...   \n",
       "4      19114.12            1824.843333                  3  ...   \n",
       "\n",
       "   Num_Credit_Inquiries  Credit_Mix Outstanding_Debt Credit_Utilization_Ratio  \\\n",
       "0                   4.0           _           809.98                26.822620   \n",
       "1                   4.0        Good           809.98                31.944960   \n",
       "2                   4.0        Good           809.98                28.609352   \n",
       "3                   4.0        Good           809.98                31.377862   \n",
       "4                   4.0        Good           809.98                24.797347   \n",
       "\n",
       "      Credit_History_Age Payment_of_Min_Amount Total_EMI_per_month  \\\n",
       "0  22 Years and 1 Months                    No           49.574949   \n",
       "1                    NaN                    No           49.574949   \n",
       "2  22 Years and 3 Months                    No           49.574949   \n",
       "3  22 Years and 4 Months                    No           49.574949   \n",
       "4  22 Years and 5 Months                    No           49.574949   \n",
       "\n",
       "   Amount_invested_monthly                 Payment_Behaviour  \\\n",
       "0        80.41529543900253   High_spent_Small_value_payments   \n",
       "1       118.28022162236736    Low_spent_Large_value_payments   \n",
       "2          81.699521264648   Low_spent_Medium_value_payments   \n",
       "3        199.4580743910713    Low_spent_Small_value_payments   \n",
       "4       41.420153086217326  High_spent_Medium_value_payments   \n",
       "\n",
       "      Monthly_Balance  \n",
       "0  312.49408867943663  \n",
       "1  284.62916249607184  \n",
       "2   331.2098628537912  \n",
       "3  223.45130972736786  \n",
       "4  341.48923103222177  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e3154-9126-4ace-b8ba-6743473696f7",
   "metadata": {},
   "source": [
    "We'll then perform data cleaning to filter out irrelevant features for our prediction. A little bit of feature engineering after might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349fe467-4d9d-40dc-9ec8-6f88fef0e32f",
   "metadata": {},
   "source": [
    "First of all, we need to look more into our 'Monthly_Balance' column, which holds more than one data type, hence detected as DTypeWarning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfc84d9-1db2-4d4c-baac-2b97e12a35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['312.49408867943663' '284.62916249607184' '331.2098628537912' ...\n",
      " 516.8090832742814 319.1649785257098 393.6736955618808]\n"
     ]
    }
   ],
   "source": [
    "print(X['Monthly_Balance'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a41b7b8-30e9-403f-b727-28252852ab81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1602</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>22 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.41529543900253</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.494089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1603</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.28022162236736</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.629162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1604</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>March</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>-500</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>22 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521264648</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.209863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1605</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>22 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.4580743910713</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.451310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1606</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>22 Years and 5 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153086217326</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.489231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID Customer_ID     Month           Name   Age          SSN Occupation  \\\n",
       "0  0x1602   CUS_0xd40   January  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "1  0x1603   CUS_0xd40  February  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "2  0x1604   CUS_0xd40     March  Aaron Maashoh  -500  821-00-0265  Scientist   \n",
       "3  0x1605   CUS_0xd40     April  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "4  0x1606   CUS_0xd40       May  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "\n",
       "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  \\\n",
       "0      19114.12            1824.843333                  3  ...   \n",
       "1      19114.12                    NaN                  3  ...   \n",
       "2      19114.12                    NaN                  3  ...   \n",
       "3      19114.12                    NaN                  3  ...   \n",
       "4      19114.12            1824.843333                  3  ...   \n",
       "\n",
       "   Num_Credit_Inquiries  Credit_Mix Outstanding_Debt Credit_Utilization_Ratio  \\\n",
       "0                   4.0           _           809.98                26.822620   \n",
       "1                   4.0        Good           809.98                31.944960   \n",
       "2                   4.0        Good           809.98                28.609352   \n",
       "3                   4.0        Good           809.98                31.377862   \n",
       "4                   4.0        Good           809.98                24.797347   \n",
       "\n",
       "      Credit_History_Age Payment_of_Min_Amount Total_EMI_per_month  \\\n",
       "0  22 Years and 1 Months                    No           49.574949   \n",
       "1                    NaN                    No           49.574949   \n",
       "2  22 Years and 3 Months                    No           49.574949   \n",
       "3  22 Years and 4 Months                    No           49.574949   \n",
       "4  22 Years and 5 Months                    No           49.574949   \n",
       "\n",
       "   Amount_invested_monthly                 Payment_Behaviour Monthly_Balance  \n",
       "0        80.41529543900253   High_spent_Small_value_payments      312.494089  \n",
       "1       118.28022162236736    Low_spent_Large_value_payments      284.629162  \n",
       "2          81.699521264648   Low_spent_Medium_value_payments      331.209863  \n",
       "3        199.4580743910713    Low_spent_Small_value_payments      223.451310  \n",
       "4       41.420153086217326  High_spent_Medium_value_payments      341.489231  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Monthly_Balance'] = pd.to_numeric(X['Monthly_Balance'], errors='coerce')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba06fa87-ce54-4f5c-bdbf-686f94b59054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e466b3-77b9-491d-a623-f73c06f2ed15",
   "metadata": {},
   "source": [
    "'ID', 'Customer_ID', 'Name', 'SSN', 'Occupation', and 'Type_of_Loan' are, for now, **irrelevant** to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf654d7e-caac-47b4-ad23-0131bf836c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop irrelevant features\n",
    "X = X.drop(columns=['ID', 'Customer_ID', 'Name', 'SSN', 'Occupation', 'Type_of_Loan'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10338ddb-901f-4469-8f29-14587a489a66",
   "metadata": {},
   "source": [
    "Furthermore, there are features that hold string values, which obviously cannot be processed by the logistic regression model. We need to convert them into one-hot encoding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7447fc0-5f19-4407-8c42-5546d2ef72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of X: (100000, 39)\n",
      "New shape of y: (100000, 3)\n"
     ]
    }
   ],
   "source": [
    "## One-hot encoding\n",
    "X = pd.get_dummies(X, columns=['Month', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour'])\n",
    "y = pd.get_dummies(y)\n",
    "print(f\"New shape of X: {X.shape}\")\n",
    "print(f\"New shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f430b316-e980-4af1-bb71-3abbec223237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31302/2337723389.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['Credit_History_Age'].replace('NA', pd.NA, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Map 'Credit_History_Age' into decimals and NaN values\n",
    "import re\n",
    "\n",
    "# Replace 'NA' with NaN\n",
    "X['Credit_History_Age'].replace('NA', pd.NA, inplace=True)\n",
    "\n",
    "# Function to extract years and months\n",
    "def extract_years_months(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    match = re.match(r'(\\d+)\\s+Years?\\s+and\\s+(\\d+)\\s+Months?', value)\n",
    "    if match:\n",
    "        years, months = map(int, match.groups())\n",
    "        return years + months / 12\n",
    "    return None\n",
    "\n",
    "# Apply the function to the column\n",
    "X['Credit_History_Age'] = X['Credit_History_Age'].apply(extract_years_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da62984-fd0d-4ab7-acec-a027b7f35a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.083333\n",
       "1          NaN\n",
       "2    22.250000\n",
       "3    22.333333\n",
       "4    22.416667\n",
       "Name: Credit_History_Age, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Credit_History_Age'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc936c-dfb3-496b-831c-760f817e2889",
   "metadata": {},
   "source": [
    "Now, we need to address NaN values as a part of data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f45efb-ed04-444c-88ed-957ce07fa28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure all values are numerical\n",
    "X_num = X.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408b910f-c3ac-4f4b-9029-2c26ad7ff08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                                    4939\n",
       "Annual_Income                                          6980\n",
       "Monthly_Inhand_Salary                                 15002\n",
       "Num_Bank_Accounts                                         0\n",
       "Num_Credit_Card                                           0\n",
       "Interest_Rate                                             0\n",
       "Num_of_Loan                                            4785\n",
       "Delay_from_due_date                                       0\n",
       "Num_of_Delayed_Payment                                 9746\n",
       "Changed_Credit_Limit                                   2091\n",
       "Num_Credit_Inquiries                                   1965\n",
       "Outstanding_Debt                                       1009\n",
       "Credit_Utilization_Ratio                                  0\n",
       "Credit_History_Age                                     9030\n",
       "Total_EMI_per_month                                       0\n",
       "Amount_invested_monthly                                8784\n",
       "Monthly_Balance                                        1209\n",
       "Month_April                                               0\n",
       "Month_August                                              0\n",
       "Month_February                                            0\n",
       "Month_January                                             0\n",
       "Month_July                                                0\n",
       "Month_June                                                0\n",
       "Month_March                                               0\n",
       "Month_May                                                 0\n",
       "Credit_Mix_Bad                                            0\n",
       "Credit_Mix_Good                                           0\n",
       "Credit_Mix_Standard                                       0\n",
       "Credit_Mix__                                              0\n",
       "Payment_of_Min_Amount_NM                                  0\n",
       "Payment_of_Min_Amount_No                                  0\n",
       "Payment_of_Min_Amount_Yes                                 0\n",
       "Payment_Behaviour_!@9#%8                                  0\n",
       "Payment_Behaviour_High_spent_Large_value_payments         0\n",
       "Payment_Behaviour_High_spent_Medium_value_payments        0\n",
       "Payment_Behaviour_High_spent_Small_value_payments         0\n",
       "Payment_Behaviour_Low_spent_Large_value_payments          0\n",
       "Payment_Behaviour_Low_spent_Medium_value_payments         0\n",
       "Payment_Behaviour_Low_spent_Small_value_payments          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ded4b04-3c8e-4c6e-af66-72d7314d5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the missing values with mean in each column\n",
    "X_num = X_num.fillna(X_num.mean())\n",
    "\n",
    "# Initialize the KNN imputer\n",
    "# imputer = KNNImputer(missing_values=np.nan, n_neighbors=5)\n",
    "\n",
    "# # Fit and transform the data\n",
    "# start_time = time.time()\n",
    "# X_imputed = imputer.fit_transform(X_num)\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f\"KNNImputer fitting time: {end_time - start_time} seconds\")\n",
    "\n",
    "# # Convert back to DataFrame\n",
    "# X_num = pd.DataFrame(X_imputed, columns=X_num.columns)\n",
    "# del X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df447e4f-561f-40f8-89bd-945d9c953d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                                   0\n",
       "Annual_Income                                         0\n",
       "Monthly_Inhand_Salary                                 0\n",
       "Num_Bank_Accounts                                     0\n",
       "Num_Credit_Card                                       0\n",
       "Interest_Rate                                         0\n",
       "Num_of_Loan                                           0\n",
       "Delay_from_due_date                                   0\n",
       "Num_of_Delayed_Payment                                0\n",
       "Changed_Credit_Limit                                  0\n",
       "Num_Credit_Inquiries                                  0\n",
       "Outstanding_Debt                                      0\n",
       "Credit_Utilization_Ratio                              0\n",
       "Credit_History_Age                                    0\n",
       "Total_EMI_per_month                                   0\n",
       "Amount_invested_monthly                               0\n",
       "Monthly_Balance                                       0\n",
       "Month_April                                           0\n",
       "Month_August                                          0\n",
       "Month_February                                        0\n",
       "Month_January                                         0\n",
       "Month_July                                            0\n",
       "Month_June                                            0\n",
       "Month_March                                           0\n",
       "Month_May                                             0\n",
       "Credit_Mix_Bad                                        0\n",
       "Credit_Mix_Good                                       0\n",
       "Credit_Mix_Standard                                   0\n",
       "Credit_Mix__                                          0\n",
       "Payment_of_Min_Amount_NM                              0\n",
       "Payment_of_Min_Amount_No                              0\n",
       "Payment_of_Min_Amount_Yes                             0\n",
       "Payment_Behaviour_!@9#%8                              0\n",
       "Payment_Behaviour_High_spent_Large_value_payments     0\n",
       "Payment_Behaviour_High_spent_Medium_value_payments    0\n",
       "Payment_Behaviour_High_spent_Small_value_payments     0\n",
       "Payment_Behaviour_Low_spent_Large_value_payments      0\n",
       "Payment_Behaviour_Low_spent_Medium_value_payments     0\n",
       "Payment_Behaviour_Low_spent_Small_value_payments      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef41deb-76fd-4b1d-a488-a40109156fb1",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d134afc-0d0e-462d-aa91-c0e07618e425",
   "metadata": {},
   "source": [
    "Feature engineering lets us create new features by combining existing ones. These new features help the model to see the relationship between features and can improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e84fe0-58d7-41ef-93af-bb097fe172d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interaction features\n",
    "X_num['Debt_to_Income_Ratio'] = X_num['Outstanding_Debt'] / X_num['Annual_Income']\n",
    "X_num['Loan_to_Income_Ratio'] = X_num['Num_of_Loan'] / X_num['Annual_Income']\n",
    "X_num['Investment_Ratio'] = X_num['Amount_invested_monthly'] / X_num['Monthly_Inhand_Salary']\n",
    "X_num['Credit_Card_Utilization'] = X_num['Credit_Utilization_Ratio'] * X_num['Num_Credit_Card']\n",
    "\n",
    "## Aggregated features\n",
    "X_num['Total_Debt'] = X_num['Outstanding_Debt'] + X_num['Total_EMI_per_month']\n",
    "\n",
    "## One-hot encoding for seasons\n",
    "## --> Winter\n",
    "X_num['Winter'] = X_num['Month_January'] + X_num['Month_February']\n",
    "## --> Spring\n",
    "X_num['Spring'] = X_num['Month_March'] + X_num['Month_April'] + X_num['Month_May']\n",
    "## --> Summer\n",
    "X_num['Summer'] = X_num['Month_June'] + X_num['Month_July'] + X_num['Month_August']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e4c28-c7aa-424c-b77b-e04a6d649a65",
   "metadata": {},
   "source": [
    "We also need to perform normalization to some features so that all features are in a virtually comparable range of values (feature scaling). We will use z-score normalization that subtracts the mean from each feature and divide the resulting value by its standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75684c34-bb54-4110-af84-9a840028085f",
   "metadata": {},
   "source": [
    "First, we will reduce the impact of **outliers** (i.e., skewed, and possibly incorrect,\n",
    "values in columns that might distort z-score normalization results) by applying natural log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6504a45-ec66-4f77-b2a5-378efb4dc73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_log = [\n",
    "    'Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n",
    "    'Num_Credit_Card',\n",
    "    'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment',\n",
    "    'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt',\n",
    "    'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month',\n",
    "    'Amount_invested_monthly', 'Monthly_Balance',\n",
    "    'Debt_to_Income_Ratio', 'Loan_to_Income_Ratio', 'Investment_Ratio', \n",
    "    'Credit_Card_Utilization', 'Total_Debt'\n",
    "]\n",
    "\n",
    "## Prevent FloatingPointError\n",
    "X_num[columns_log] = X_num[columns_log].map(lambda x: x if x >= 0 else 0.01)\n",
    "\n",
    "## Apply log transformation to necessary columns\n",
    "X_num[columns_log] = np.log1p(X_num[columns_log])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4b188-0f8f-40bb-8f6b-e1b19450dc62",
   "metadata": {},
   "source": [
    "We can then proceed for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07bee17f-5bdc-41b7-944e-e020477c9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We want to normalize all columns except one-hot encoding vectors\n",
    "columns_norm = [\n",
    "    'Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', \n",
    "    'Num_Credit_Card',\n",
    "    'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment',\n",
    "    'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt',\n",
    "    'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month',\n",
    "    'Amount_invested_monthly', 'Monthly_Balance',\n",
    "    'Debt_to_Income_Ratio', 'Loan_to_Income_Ratio', 'Investment_Ratio', \n",
    "    'Credit_Card_Utilization', 'Total_Debt'\n",
    "]\n",
    "\n",
    "## Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Fit and transform the selected columns\n",
    "X_num[columns_norm] = scaler.fit_transform(X_num[columns_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5433c7bf-76db-4231-bf35-ce6d0124215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.1441\n",
       "1   -0.1441\n",
       "2   -0.1441\n",
       "3   -0.1441\n",
       "4   -0.1441\n",
       "Name: Debt_to_Income_Ratio, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num['Debt_to_Income_Ratio'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "625511f3-2f45-46b1-8d8d-7b3439d29991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.409512\n",
       "1   -0.409512\n",
       "2   -0.409512\n",
       "3   -0.409512\n",
       "4   -0.409512\n",
       "Name: Num_Credit_Card, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num['Num_Credit_Card'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112f27d-3673-4f07-ba4b-10e8246cf68e",
   "metadata": {},
   "source": [
    "## Risk minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d198a-686d-41a2-8db0-53db37783c2e",
   "metadata": {},
   "source": [
    "We need to come to an understanding that logistic regression model cannot be trained on the target label of three possible binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40eedbf1-30ee-4560-adda-1eee27b3e4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Good</th>\n",
       "      <th>Poor</th>\n",
       "      <th>Standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Good   Poor  Standard\n",
       "0  True  False     False\n",
       "1  True  False     False\n",
       "2  True  False     False\n",
       "3  True  False     False\n",
       "4  True  False     False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf6a51-d7df-429d-b9d9-58eedd9eb15d",
   "metadata": {},
   "source": [
    "Let's assume that the global finance company we're working with is not looking for more market expansion and is trying to minimize loan risk. Therefore, we want to label parties with **Good** credit scores as being eligible for loans, while the rest are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c664fe69-3232-45b4-8fbe-c672c2c19ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new binary label\n",
    "y['Target'] = y['Good']\n",
    "\n",
    "## Drop the original one-hot encoded columns\n",
    "y = y.drop(columns=['Good', 'Standard', 'Poor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3401fcc-8904-4c0d-bd18-f33b0e09ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61296dd4-850f-4964-a19b-26987958daad",
   "metadata": {},
   "source": [
    "## Using feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade3bfd-848d-4179-a696-31eccb0371d8",
   "metadata": {},
   "source": [
    "Use feature selection to reduce dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "184e32dc-66a5-43ac-af9c-2118fff12b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_selection(X, y, k):\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    y_new = y.values.ravel()\n",
    "    X_new = pd.DataFrame(selector.fit_transform(X, y_new), columns=X.columns[selector.get_support()])\n",
    "\n",
    "    print(f\"Selected features shape: {X_new.shape}\")\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732f8884-bdf9-437e-81e0-8e6d4d55f121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape: (100000, 32)\n"
     ]
    }
   ],
   "source": [
    "X_fs = apply_selection(X_num, y, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8323b09-2c8a-4e56-8783-840e378f70ee",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e67b5852-cde1-44c9-a243-e2c055d7a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape is: (1024, 47)\n",
      "Train Y shape is: (1024, 1)\n",
      "Test X shape is: (1024, 47)\n",
      "Test Y shape is: (1024, 1)\n"
     ]
    }
   ],
   "source": [
    "## NUM_SAMPLES is the combination of all sets (NUM_TRAINING + NUM_TEST)\n",
    "NUM_SAMPLES = 2048\n",
    "COMPARE_TO_R_REF = False\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "\n",
    "## Slice data into NumPy arrays and split into training and test sets\n",
    "X_train, X_test, y_train, y_test = slice_split(\n",
    "    X_num, y,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    compare_to_r_ref=COMPARE_TO_R_REF\n",
    ")\n",
    "\n",
    "## n = num_of_features\n",
    "n = X_train.shape[1]\n",
    "\n",
    "# Same shape as Marcelo's reference code\n",
    "betas = np.zeros((n, ))\n",
    "# betas = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b98a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples: 818\n",
      "Number of positive samples: 206\n",
      "Ratio neg/pos: 3.970873786407767\n"
     ]
    }
   ],
   "source": [
    "## See ratio between negative and positive samples\n",
    "num_neg = np.sum(y_train == 0)  \n",
    "num_pos = np.sum(y_train == 1)  \n",
    "print(f\"Number of negative samples: {num_neg}\")\n",
    "print(f\"Number of positive samples: {num_pos}\")\n",
    "print(f\"Ratio neg/pos: {num_neg/num_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d3dac9a-80a4-4212-b985-c7185b4b645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420f71b-22cd-4359-81e9-7e3611916ce9",
   "metadata": {},
   "source": [
    "## Applying Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3c68c-afce-425d-be4c-5a32f48dd375",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) allows for a reduced dataset, meaning the new dataset will have a small number of new features (called the principal components), which explains all original features. \n",
    "\n",
    "How well these new features explain the original ones is parameterized by explained variance ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d3d70-5a61-4c01-85cb-bfc8ae877a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Number of components after PCA: {X_train_pca.shape[1]}\")\n",
    "    \n",
    "    return X_train_pca, X_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f5d07-cad5-458e-9b67-c5d49c28856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = apply_pca(X_train, X_test, n_components=32)\n",
    "\n",
    "## n = num_of_features\n",
    "n = X_train.shape[1]\n",
    "print(f\"n = {n}\")\n",
    "\n",
    "# Same shape as Marcelo's reference code\n",
    "betas = np.zeros((n, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93a652-ddc7-4341-bf03-4312e8aaa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train X shape is: {X_train.shape}\")\n",
    "print(f\"Train Y shape is: {y_train.shape}\")\n",
    "print(f\"Test X shape is: {X_test.shape}\")\n",
    "print(f\"Test Y shape is: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc52987-85d1-4be1-96a5-921d52f46586",
   "metadata": {},
   "source": [
    "## Nesterov model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4ac1694-7e68-4e4a-999a-b60e3b564b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "@njit\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas   # A vector of linear_predictions/logits z = train_x @ weights\n",
    "    if dbg:\n",
    "        print(f\"Length of Logits: {len(preds)}\")\n",
    "    return np.expand_dims(sigmoid(preds), -1)   # Shape: (m, 1)\n",
    "\n",
    "@njit\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)   # A vector of logistic predictions y_hat = sigmoid(z)\n",
    "    gradient = -train_x.T @ (train_y - preds) / len(train_y)\n",
    "    return gradient   # Shape: (10, 1) == Rows correspond to num_features\n",
    "    ## This function is used to update the values of betas: w_new = w_old + lr * gradient\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))   # h: hypothesis, basically preds/y_hat\n",
    "    t1 = np.matmul(-y.T, np.log(np.clip(h, 0.000000000000001, np.max(h))))\n",
    "    t2_a = (1 - y.T)\n",
    "    t2_b = np.log(np.clip(1 - h, 0.000000000000001, np.max(1 - h)))  # Used to get numerical issues\n",
    "    ## np.clip() function prevents computing the log of 0, by taking the minimum of 1e-15.\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "\n",
    "    return ((t1 - t2) / m)[0]   # Shape: (1,) == scalar value\n",
    "\n",
    "def nesterov(betas, epochs, patience, lr, mu, train_x, train_y):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    check_early = 0\n",
    "    best_loss = float('inf')\n",
    "    best_epochs_list = []\n",
    "\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    for i in tqdm.trange(epochs):\n",
    "    # for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "\n",
    "        ## Assign updated weights into phi_prime\n",
    "        phi_prime = theta - lr * np.squeeze(gradient)   # np.squeeze() removes single dimensions --> shape (10,)\n",
    "        \n",
    "        ## Nesterov acceleration process\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            ## If current updated weight (phi_prime) < previous weight (phi), \n",
    "            ## The updated weight theta will be even smaller.\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "        phi = phi_prime   # phi is then the weight of the previous epoch/update if Nesterov is used\n",
    "\n",
    "        # ## Ditching Nesterov for now\n",
    "        # theta = phi_prime   \n",
    "        loss = cost(train_x, train_y, theta)\n",
    "\n",
    "        ## Early stopping\n",
    "        if patience > 0:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = i\n",
    "                best_theta = theta\n",
    "                best_epochs_list.append(best_epoch)\n",
    "                check_early = 0\n",
    "            else:\n",
    "                check_early += 1\n",
    "                if check_early >= patience:\n",
    "                    print(f\"Early stopping at {patience} epochs after {best_epoch} with best loss {best_loss}\")\n",
    "                    return nesterov_loss[:best_epoch + 1], best_theta, phi, best_epochs_list\n",
    "        else:\n",
    "            best_epoch = epochs - 1\n",
    "            best_theta = theta\n",
    "\n",
    "        ## Update list\n",
    "        nesterov_loss[i] = loss\n",
    "\n",
    "        # print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return nesterov_loss[:best_epoch + 1], best_theta, phi, best_epochs_list\n",
    "\n",
    "def sgd(betas, epochs, patience, lr, train_x, train_y):\n",
    "    import copy\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    check_early = 0\n",
    "    best_loss = float('inf')\n",
    "    best_epochs_list = []\n",
    "\n",
    "    sgd_loss = [0 for _ in range(epochs)]\n",
    "    for i in tqdm.trange(epochs):\n",
    "        ## Shuffle training data for each epoch\n",
    "        indices = np.random.permutation(train_x.shape[0])\n",
    "\n",
    "        for j in indices:\n",
    "            x_j = train_x[j:j+1]\n",
    "            y_j = train_y[j:j+1]\n",
    "\n",
    "            gradient = calculate_gradient(x_j, y_j, theta, fwd, dbg=False)\n",
    "\n",
    "            ## Assign updated weights into phi_prime\n",
    "            phi_prime = theta - lr * np.squeeze(gradient)   # np.squeeze() removes single dimensions --> shape (10,)\n",
    "\n",
    "            theta = phi_prime   # SGD does not use Nesterov acceleration\n",
    "        \n",
    "        loss = cost(train_x, train_y, theta)\n",
    "\n",
    "        ## Early stopping\n",
    "        if patience > 0:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = i\n",
    "                best_theta = theta\n",
    "                best_epochs_list.append(best_epoch)\n",
    "                check_early = 0\n",
    "            else:\n",
    "                check_early += 1\n",
    "                if check_early >= patience:\n",
    "                    print(f\"Early stopping at {patience} epochs after {best_epoch} with best loss {best_loss}\")\n",
    "                    return sgd_loss[:best_epoch + 1], best_theta, best_epochs_list\n",
    "        else:\n",
    "            best_epoch = epochs - 1\n",
    "            best_theta = theta\n",
    "\n",
    "        ## Update list\n",
    "        sgd_loss[i] = loss\n",
    "\n",
    "        # print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return sgd_loss[:best_epoch + 1], best_theta, best_epochs_list\n",
    "\n",
    "def minibgd(betas, epochs, patience, lr, train_x, train_y, batch_size=32):\n",
    "    import copy\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    check_early = 0\n",
    "    best_loss = float('inf')\n",
    "    best_epochs_list = []\n",
    "\n",
    "    mbgd_loss = [0 for _ in range(epochs)]\n",
    "    for i in tqdm.trange(epochs):\n",
    "\n",
    "        for j in range(0, train_x.shape[0], batch_size):\n",
    "            batch_x = train_x[j:j+batch_size]\n",
    "            batch_y = train_y[j:j+batch_size]\n",
    "\n",
    "            gradient = calculate_gradient(batch_x, batch_y, theta, fwd, dbg=False)\n",
    "\n",
    "            ## Assign updated weights into phi_prime\n",
    "            phi_prime = theta - lr * np.squeeze(gradient)   # np.squeeze() removes single dimensions --> shape (10,)\n",
    "\n",
    "            theta = phi_prime   # SGD does not use Nesterov acceleration\n",
    "        \n",
    "        loss = cost(train_x, train_y, theta)\n",
    "\n",
    "        ## Early stopping\n",
    "        if patience > 0:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_epoch = i\n",
    "                best_theta = theta\n",
    "                best_epochs_list.append(best_epoch)\n",
    "                check_early = 0\n",
    "            else:\n",
    "                check_early += 1\n",
    "                if check_early >= patience:\n",
    "                    print(f\"Early stopping at {patience} epochs after {best_epoch} with best loss {best_loss}\")\n",
    "                    return mbgd_loss[:best_epoch + 1], best_theta, best_epochs_list\n",
    "        else:\n",
    "            best_epoch = epochs - 1\n",
    "            best_theta = theta\n",
    "\n",
    "        ## Update list\n",
    "        mbgd_loss[i] = loss\n",
    "\n",
    "        # print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return mbgd_loss[:best_epoch + 1], best_theta, best_epochs_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "682bb6fb-95bc-4d2d-b8f6-2cff40112de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inputs are of the correct type\n",
    "betas = np.array(betas, dtype=np.float64)\n",
    "X_train = np.array(X_train, dtype=np.float64)\n",
    "y_train = np.array(y_train, dtype=np.float64)\n",
    "X_test = np.array(X_test, dtype=np.float64)\n",
    "y_test = np.array(y_test, dtype=np.float64)\n",
    "lr = float(lr)\n",
    "mu = float(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0271d02-84d7-47cf-bc92-7a3c41b22631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 151.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# losses, theta, phi, best_epochs_list = nesterov(betas, 200, -1, lr, mu, X_train, y_train)\n",
    "# losses, theta, best_epochs_list = sgd(betas, 200, -1, 0.01, X_train, y_train)\n",
    "losses, theta, best_epochs_list = minibgd(betas, 200, -1, lr, X_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb5e2d30-f268-4348-9bb0-10182cf18bdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.42125106019865904\n",
      "1: 0.3693794905971943\n",
      "2: 0.3478817434046736\n",
      "3: 0.3360000116419437\n",
      "4: 0.32829000621174265\n",
      "5: 0.32278365708616535\n",
      "6: 0.318604228099489\n",
      "7: 0.3152993904858073\n",
      "8: 0.31260913963261205\n",
      "9: 0.31037131716377847\n",
      "10: 0.3084782733762296\n",
      "11: 0.3068550096406488\n",
      "12: 0.30544726565806873\n",
      "13: 0.30421459506926485\n",
      "14: 0.30312611758549113\n",
      "15: 0.30215779204371856\n",
      "16: 0.3012905973746678\n",
      "17: 0.3005092790937982\n",
      "18: 0.2998014612715736\n",
      "19: 0.29915700239436105\n",
      "20: 0.29856751859097247\n",
      "21: 0.2980260245504902\n",
      "22: 0.2975266589880438\n",
      "23: 0.29706447199646524\n",
      "24: 0.29663525844593974\n",
      "25: 0.29623542614501086\n",
      "26: 0.29586189057857637\n",
      "27: 0.29551199019538477\n",
      "28: 0.29518341774424944\n",
      "29: 0.294874164256499\n",
      "30: 0.2945824730739405\n",
      "31: 0.2943068019146685\n",
      "32: 0.2940457914129708\n",
      "33: 0.2937982389054721\n",
      "34: 0.29356307649227553\n",
      "35: 0.2933393525996698\n",
      "36: 0.2931262164246643\n",
      "37: 0.2929229047619365\n",
      "38: 0.29272873080859263\n",
      "39: 0.29254307461734436\n",
      "40: 0.2923653749286931\n",
      "41: 0.29219512216082344\n",
      "42: 0.29203185237469026\n",
      "43: 0.2918751420631943\n",
      "44: 0.2917246036388937\n",
      "45: 0.2915798815155755\n",
      "46: 0.29144064869612973\n",
      "47: 0.2913066037932658\n",
      "48: 0.2911774684212533\n",
      "49: 0.29105298490652154\n",
      "50: 0.29093291427297685\n",
      "51: 0.2908170344645928\n",
      "52: 0.29070513877342374\n",
      "53: 0.2905970344458932\n",
      "54: 0.2904925414441525\n",
      "55: 0.2903914913426399\n",
      "56: 0.29029372634278017\n",
      "57: 0.2901990983911502\n",
      "58: 0.29010746838845974\n",
      "59: 0.2900187054784179\n",
      "60: 0.2899326864070231\n",
      "61: 0.2898492949440703\n",
      "62: 0.2897684213597409\n",
      "63: 0.28968996195006275\n",
      "64: 0.2896138186058198\n",
      "65: 0.28953989842016903\n",
      "66: 0.2894681133308144\n",
      "67: 0.289398379793092\n",
      "68: 0.28933061848076136\n",
      "69: 0.2892647540116784\n",
      "70: 0.2892007146958581\n",
      "71: 0.28913843230372116\n",
      "72: 0.28907784185257096\n",
      "73: 0.28901888140956733\n",
      "74: 0.2889614919096531\n",
      "75: 0.2889056169870602\n",
      "76: 0.2888512028191677\n",
      "77: 0.28879819798161444\n",
      "78: 0.2887465533136838\n",
      "79: 0.2886962217930774\n",
      "80: 0.2886471584192853\n",
      "81: 0.28859932010483813\n",
      "82: 0.2885526655737964\n",
      "83: 0.28850715526689485\n",
      "84: 0.28846275125281473\n",
      "85: 0.28841941714510616\n",
      "86: 0.2883771180243263\n",
      "87: 0.28833582036499905\n",
      "88: 0.28829549196703713\n",
      "89: 0.28825610189129797\n",
      "90: 0.28821762039897425\n",
      "91: 0.2881800188945462\n",
      "92: 0.28814326987204264\n",
      "93: 0.28810734686438305\n",
      "94: 0.2880722243955878\n",
      "95: 0.2880378779356627\n",
      "96: 0.2880042838579792\n",
      "97: 0.28797141939898574\n",
      "98: 0.28793926262009695\n",
      "99: 0.2879077923716219\n",
      "100: 0.2878769882586003\n",
      "101: 0.28784683060842675\n",
      "102: 0.2878173004401524\n",
      "103: 0.28778837943535934\n",
      "104: 0.2877600499105133\n",
      "105: 0.28773229479070445\n",
      "106: 0.2877050975846944\n",
      "107: 0.28767844236119194\n",
      "108: 0.2876523137262848\n",
      "109: 0.28762669680196273\n",
      "110: 0.2876015772056674\n",
      "111: 0.28757694103081155\n",
      "112: 0.2875527748282134\n",
      "113: 0.28752906558839475\n",
      "114: 0.2875058007246958\n",
      "115: 0.28748296805716106\n",
      "116: 0.28746055579715635\n",
      "117: 0.2874385525326758\n",
      "118: 0.28741694721430344\n",
      "119: 0.28739572914179495\n",
      "120: 0.28737488795124616\n",
      "121: 0.2873544136028189\n",
      "122: 0.2873342963689957\n",
      "123: 0.2873145268233356\n",
      "124: 0.2872950958297066\n",
      "125: 0.2872759945319706\n",
      "126: 0.28725721434409845\n",
      "127: 0.2872387469406942\n",
      "128: 0.28722058424790753\n",
      "129: 0.28720271843471834\n",
      "130: 0.28718514190457134\n",
      "131: 0.28716784728734845\n",
      "132: 0.2871508274316602\n",
      "133: 0.28713407539744207\n",
      "134: 0.2871175844488416\n",
      "135: 0.28710134804738346\n",
      "136: 0.2870853598453984\n",
      "137: 0.28706961367970546\n",
      "138: 0.2870541035655355\n",
      "139: 0.2870388236906849\n",
      "140: 0.2870237684098903\n",
      "141: 0.2870089322394129\n",
      "142: 0.28699430985182556\n",
      "143: 0.28697989607099167\n",
      "144: 0.2869656858672288\n",
      "145: 0.286951674352649\n",
      "146: 0.2869378567766677\n",
      "147: 0.28692422852167543\n",
      "148: 0.2869107850988639\n",
      "149: 0.28689752214420144\n",
      "150: 0.28688443541455066\n",
      "151: 0.2868715207839231\n",
      "152: 0.28685877423986506\n",
      "153: 0.2868461918799695\n",
      "154: 0.28683376990850884\n",
      "155: 0.2868215046331831\n",
      "156: 0.2868093924619812\n",
      "157: 0.2867974299001472\n",
      "158: 0.2867856135472512\n",
      "159: 0.28677394009435836\n",
      "160: 0.2867624063212932\n",
      "161: 0.2867510090939951\n",
      "162: 0.28673974536196273\n",
      "163: 0.28672861215578155\n",
      "164: 0.2867176065847341\n",
      "165: 0.28670672583448853\n",
      "166: 0.2866959671648617\n",
      "167: 0.2866853279076559\n",
      "168: 0.2866748054645659\n",
      "169: 0.286664397305152\n",
      "170: 0.28665410096487964\n",
      "171: 0.2866439140432212\n",
      "172: 0.2866338342018176\n",
      "173: 0.2866238591626988\n",
      "174: 0.2866139867065606\n",
      "175: 0.2866042146710952\n",
      "176: 0.2865945409493744\n",
      "177: 0.2865849634882827\n",
      "178: 0.2865754802870001\n",
      "179: 0.2865660893955307\n",
      "180: 0.2865567889132778\n",
      "181: 0.28654757698766203\n",
      "182: 0.2865384518127824\n",
      "183: 0.28652941162811774\n",
      "184: 0.28652045471726784\n",
      "185: 0.28651157940673316\n",
      "186: 0.28650278406473073\n",
      "187: 0.2864940671000462\n",
      "188: 0.28648542696092044\n",
      "189: 0.28647686213396883\n",
      "190: 0.2864683711431337\n",
      "191: 0.2864599525486672\n",
      "192: 0.28645160494614486\n",
      "193: 0.2864433269655076\n",
      "194: 0.2864351172701332\n",
      "195: 0.28642697455593363\n",
      "196: 0.2864188975504799\n",
      "197: 0.28641088501215206\n",
      "198: 0.2864029357293141\n",
      "199: 0.2863950485195125\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(losses)):\n",
    "    print(f\"{j}: {losses[j]}\", end='\\n')\n",
    "# Ideal Gradient (800 epochs) #\n",
    "## seed(42), lr = 0.001, mu = 0.3 --> loss = 0.5433165928958901\n",
    "## seed(42), lr = 0.001, mu = 0.5 --> loss = 0.5139704562064134\n",
    "\n",
    "# Oscillating Gradient (800 epochs) #\n",
    "## seed(42), lr = 0.003, mu = 0.5 --> loss = 0.49509424569059735\n",
    "## seed(42), lr = 0.003, mu = 0.6 --> loss = 0.4102733269497619\n",
    "\n",
    "# Early stopping (patience = 50) #\n",
    "## seed(42), lr = 0.003, mu = 0.5 --> 964: 0.410228534339208\n",
    "## seed(42), lr = 0.003, mu = 0.6 --> 422: 0.46334269494781627\n",
    "\n",
    "# Ideal Gradient (800 epochs) with Feature Engineering #\n",
    "## seed(42), lr = 0.001, mu = 0.3 --> loss = 0.523951850559082\n",
    "## seed(42), lr = 0.001, mu = 0.5 --> loss = 0.4922252143522289\n",
    "\n",
    "# Early stopping (patience = 50) with Feature Engineering #\n",
    "## seed(42), lr = 0.003, mu = 0.5 --> 739: 0.41164361016071044\n",
    "## seed(42), lr = 0.003, mu = 0.6 --> 314: 0.4688941580652026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "476c796f-207e-442b-ad72-e9716763c7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(best_epochs_list)):\n",
    "    print(f\"{j}: {best_epochs_list[j]}\", end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbdfe00a-3a2c-4552-81cf-276f49b0eb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1437495 ,  0.03777745,  0.11725458, -0.17135686, -0.17610091,\n",
       "        0.07257256, -0.42476234, -0.32293601,  0.02841478, -0.05726835,\n",
       "       -0.09527048, -0.1234824 ,  0.04065134,  0.15703102,  0.27538635,\n",
       "        0.0701872 ,  0.13025743, -0.19517463, -0.17656722, -0.25464855,\n",
       "       -0.23849051, -0.09356381, -0.15213365, -0.15677825, -0.16665692,\n",
       "       -0.3194744 ,  0.22000199, -0.93197905, -0.40256208, -0.25322962,\n",
       "       -0.21853602, -0.9622479 , -0.13740634, -0.20394414, -0.25258636,\n",
       "       -0.09026297, -0.20241603, -0.16243453, -0.38496316,  0.08435517,\n",
       "       -0.15761871, -0.07988609, -0.26570654,  0.1459805 , -0.49313906,\n",
       "       -0.51860981, -0.42226468])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224970a-dd25-48f1-84b9-34b7f75b5558",
   "metadata": {},
   "source": [
    "## Model performance on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f24da-bee9-41ce-9496-a6a7d4ef66f8",
   "metadata": {},
   "source": [
    "We can test the performance of the model through its confusion matrix, F1 score, and accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dc532-cdd6-4e7d-b420-e1f932155e94",
   "metadata": {},
   "source": [
    "First, we predict on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1b1b0a7-3759-491d-a2be-255da74061b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On training data\n",
    "pred = fwd(X_train, theta, dbg=False)\n",
    "\n",
    "## Decision (Threshold = 0.5)\n",
    "y_train_hat = (pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daeeb20c-970f-4ad6-90b8-fdb4aaf80dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec33b49e-a044-4fb4-83a1-014773609e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "736d05c1-d3e8-4f96-b3d8-a77e0baeb242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[771  47]\n",
      " [ 98 108]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e758c39-d892-4bae-9850-e4f198cc1adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5983379501385041\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39363b39-a534-4dd2-8b62-4d0584334cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6967741935483871\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87bd042a-d37e-42da-a22b-30ffca437722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5242718446601942\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a6baea1-60a5-48cb-8f99-099a9cf7f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8983549742445462\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e550946e-d85e-4f1d-a61f-45b1023c2adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8583984375\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a282797-cbb6-4758-98fc-0493a8806112",
   "metadata": {},
   "source": [
    "## Model performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e923c-5aa5-43a1-9368-08a1b6d89162",
   "metadata": {},
   "source": [
    "Now, we predict on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f7563e6-be5e-4eac-94b5-fe0403d2a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On test data\n",
    "\n",
    "pred = fwd(X_test, theta, dbg=False)\n",
    "\n",
    "## Decision (Threshold = 0.5)\n",
    "y_test_hat = (pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65b8cbab-e86f-422b-9e28-6c757710fa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7243e085-bec0-4925-a951-6176ec93d355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12b74855-2278-4ca2-8666-ef44f2570b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[753  60]\n",
      " [107 104]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28d2b97d-3609-4d17-9c64-f3b70ed67fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546666666666666\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8630873e-a3d8-48ee-99d9-a1f05e6ca0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8737226234821591\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "964b4d21-ad2e-435c-a411-8912ce882b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8369140625\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eddcbbf7-a40b-45b1-bf8e-72ae9cd0f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6341463414634146\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd69d618-cca3-4db8-b7d0-72c7ded9353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4928909952606635\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05df93",
   "metadata": {},
   "source": [
    "Sweep F1 score across different threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6080b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.27, Best F1: 0.634\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 101)\n",
    "f1s = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_test_hat_sweep = (pred >= t).astype(int)\n",
    "    f1s.append(f1_score(y_test, y_test_hat_sweep))\n",
    "\n",
    "best_t = thresholds[np.argmax(f1s)]\n",
    "best_f1 = max(f1s)\n",
    "\n",
    "print(f\"Best threshold: {best_t:.2f}, Best F1: {best_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f60e83-7208-489b-9e46-b727051d0873",
   "metadata": {},
   "source": [
    "## Write to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02b3c5af-1c3f-452e-9f2a-4d3fe178e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a DataFrame\n",
    "X_train_csv = pd.DataFrame(X_train)\n",
    "y_train_csv = pd.DataFrame(y_train)\n",
    "X_test_csv = pd.DataFrame(X_test)\n",
    "y_test_csv = pd.DataFrame(y_test)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "X_train_csv.to_csv(\"../cscore_data/X_train_1024fs.csv\", index=False)\n",
    "y_train_csv.to_csv(\"../cscore_data/y_train_1024fs.csv\", index=False)\n",
    "X_test_csv.to_csv(\"../cscore_data/X_test_1024fs.csv\", index=False)\n",
    "y_test_csv.to_csv(\"../cscore_data/y_test_1024fs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aec99244-3473-4416-b2fe-66a81ce93f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a70a0e2d-1bdb-4844-93b0-a88ced8e16b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.460089</td>\n",
       "      <td>0.319067</td>\n",
       "      <td>0.636022</td>\n",
       "      <td>0.771718</td>\n",
       "      <td>-0.172056</td>\n",
       "      <td>0.847819</td>\n",
       "      <td>0.408311</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>0.447042</td>\n",
       "      <td>1.104410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.324485</td>\n",
       "      <td>-0.410564</td>\n",
       "      <td>0.173646</td>\n",
       "      <td>0.423971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.366288</td>\n",
       "      <td>0.305226</td>\n",
       "      <td>0.626379</td>\n",
       "      <td>-0.003572</td>\n",
       "      <td>0.202622</td>\n",
       "      <td>-0.866501</td>\n",
       "      <td>1.034754</td>\n",
       "      <td>0.143579</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.744293</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.479415</td>\n",
       "      <td>-0.409154</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360107</td>\n",
       "      <td>-0.174785</td>\n",
       "      <td>-0.108077</td>\n",
       "      <td>-1.408773</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>-0.711485</td>\n",
       "      <td>0.408311</td>\n",
       "      <td>-0.145735</td>\n",
       "      <td>-1.047162</td>\n",
       "      <td>0.288454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.395609</td>\n",
       "      <td>-0.895605</td>\n",
       "      <td>0.022229</td>\n",
       "      <td>-0.236370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081902</td>\n",
       "      <td>-0.089745</td>\n",
       "      <td>0.040337</td>\n",
       "      <td>0.771718</td>\n",
       "      <td>0.202622</td>\n",
       "      <td>0.292650</td>\n",
       "      <td>0.110895</td>\n",
       "      <td>0.855789</td>\n",
       "      <td>0.673314</td>\n",
       "      <td>-1.003964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.066335</td>\n",
       "      <td>1.138855</td>\n",
       "      <td>0.480004</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.049991</td>\n",
       "      <td>0.992729</td>\n",
       "      <td>1.489341</td>\n",
       "      <td>-0.236773</td>\n",
       "      <td>0.202622</td>\n",
       "      <td>-1.563541</td>\n",
       "      <td>0.408311</td>\n",
       "      <td>-0.641981</td>\n",
       "      <td>-0.543955</td>\n",
       "      <td>-2.285441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555817</td>\n",
       "      <td>-1.146745</td>\n",
       "      <td>0.414829</td>\n",
       "      <td>0.262347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.460089  0.319067  0.636022  0.771718 -0.172056  0.847819  0.408311   \n",
       "1 -0.366288  0.305226  0.626379 -0.003572  0.202622 -0.866501  1.034754   \n",
       "2  0.360107 -0.174785 -0.108077 -1.408773  0.028710 -0.711485  0.408311   \n",
       "3  0.081902 -0.089745  0.040337  0.771718  0.202622  0.292650  0.110895   \n",
       "4 -0.049991  0.992729  1.489341 -0.236773  0.202622 -1.563541  0.408311   \n",
       "\n",
       "         7         8         9   ...   22   23   24   25        26        27  \\\n",
       "0  0.007451  0.447042  1.104410  ...  1.0  0.0  1.0  0.0 -0.324485 -0.410564   \n",
       "1  0.143579  0.004386  0.744293  ...  1.0  1.0  0.0  0.0 -0.479415 -0.409154   \n",
       "2 -0.145735 -1.047162  0.288454  ...  0.0  1.0  0.0  0.0 -0.395609 -0.895605   \n",
       "3  0.855789  0.673314 -1.003964  ...  1.0  0.0  0.0  1.0 -0.066335  1.138855   \n",
       "4 -0.641981 -0.543955 -2.285441  ...  0.0  1.0  0.0  0.0 -0.555817 -1.146745   \n",
       "\n",
       "         28        29   30   31  \n",
       "0  0.173646  0.423971  0.0  1.0  \n",
       "1 -0.012949  0.025207  0.0  1.0  \n",
       "2  0.022229 -0.236370  0.0  0.0  \n",
       "3  0.480004  0.454371  0.0  1.0  \n",
       "4  0.414829  0.262347  0.0  1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_csv[X_train_csv.columns[:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523c5a8-2f97-45c7-aa55-48e47d1e14b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
